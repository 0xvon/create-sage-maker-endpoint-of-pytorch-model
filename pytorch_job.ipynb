{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchでLSTMモデル運用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 96.1 ms, total: 1.38 s\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorchでのLSTMモデルサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, inputDim, hiddenDim, outputDim):\n",
    "        super(Predictor, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = inputDim,\n",
    "                            hidden_size = hiddenDim,\n",
    "                            batch_first = True)\n",
    "        self.output_layer = nn.Linear(hiddenDim, outputDim)\n",
    "    \n",
    "    def forward(self, inputs, hidden0=None):\n",
    "        output, (hidden, cell) = self.rnn(inputs, hidden0) #LSTM層\n",
    "        output = self.output_layer(output[:, -1, :]) #全結合層\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す。\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    batch_t = []\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - 1)\n",
    "        batch_x.append(train_x[idx])\n",
    "        batch_t.append(train_t[idx])\n",
    "    \n",
    "    return torch.tensor(batch_x), torch.tensor(batch_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss: 3.777, training_accuracy: 0.32670, test_accuracy: 0.49015\n",
      "2 loss: 0.828, training_accuracy: 0.52902, test_accuracy: 0.51157\n",
      "3 loss: 0.756, training_accuracy: 0.57182, test_accuracy: 0.55013\n",
      "4 loss: 0.695, training_accuracy: 0.60602, test_accuracy: 0.55698\n",
      "5 loss: 0.591, training_accuracy: 0.65835, test_accuracy: 0.59640\n",
      "6 loss: 0.446, training_accuracy: 0.72470, test_accuracy: 0.61611\n",
      "7 loss: 0.290, training_accuracy: 0.80992, test_accuracy: 0.67266\n",
      "8 loss: 0.291, training_accuracy: 0.81226, test_accuracy: 0.68723\n",
      "9 loss: 0.262, training_accuracy: 0.83086, test_accuracy: 0.66495\n",
      "10 loss: 0.269, training_accuracy: 0.82656, test_accuracy: 0.66153\n"
     ]
    }
   ],
   "source": [
    "epochs_num = 10\n",
    "hidden_size = 100\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "\n",
    "training_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "\n",
    "train_x = X_train.tolist()\n",
    "train_t = y_train.tolist()\n",
    "test_x = X_test.tolist()\n",
    "test_t = y_test.tolist()\n",
    "\n",
    "model = Predictor(1, hidden_size, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(epochs_num):\n",
    "    # training\n",
    "    running_loss = 0.0\n",
    "    training_accuracy = 0.0\n",
    "    for i in range(int(training_size / batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data, label = mkRandomBatch(train_x, train_t, batch_size)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data\n",
    "        training_accuracy += np.sum(np.abs((output.data - label.data).numpy()) < 0.1)\n",
    "\n",
    "    #test\n",
    "    test_accuracy = 0.0\n",
    "    for i in range(int(test_size / batch_size)):\n",
    "        offset = i * batch_size\n",
    "        data, label = torch.tensor(test_x[offset:offset+batch_size]), torch.tensor(test_t[offset:offset+batch_size])\n",
    "        output = model(data, None)\n",
    "\n",
    "        test_accuracy += np.sum(np.abs((output.data - label.data).numpy()) < 0.1)\n",
    "\n",
    "    training_accuracy /= training_size\n",
    "    test_accuracy /= test_size\n",
    "\n",
    "    print('%d loss: %.3f, training_accuracy: %.5f, test_accuracy: %.5f' % (\n",
    "        epoch + 1, running_loss, training_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMakerにデプロイ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(data, n_prev=50):\n",
    "    docX, docY = [], []\n",
    "    for i in range(len(data) - n_prev):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        docX.append(data.iloc[i - 1:i + n_prev - 1].values)\n",
    "        docY.append(data.iloc[i + n_prev].values)\n",
    "    alsX = np.array(docX)\n",
    "    alsY = np.array(docY)\n",
    "\n",
    "    return alsX, alsY\n",
    "\n",
    "\n",
    "# 学習用とテスト用データを分割、ただし分割する際に_load_data()を適用\n",
    "def train_test_split(df, test_size=0.1, n_prev=50):\n",
    "    \"\"\"\n",
    "    This just splits data to training and testing parts\n",
    "    \"\"\"\n",
    "    ntrn = round(len(df) * (1 - test_size))\n",
    "    ntrn = int(ntrn)\n",
    "    X_train, y_train = _load_data(df.iloc[0:ntrn], n_prev)\n",
    "    X_test, y_test = _load_data(df.iloc[ntrn:], n_prev)\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "\n",
    "def inverse_original_scale(x):\n",
    "    x = scaler.inverse_transform(x.reshape(1, -1))\n",
    "    x = np.exp(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "df_code_date_hourly = pd.read_csv('./code_run_num_hourly.csv')\n",
    "split_date = lambda x: x.split(\" \")[0]\n",
    "df_code_date_hourly[\"date\"] = list(map(split_date, df_code_date_hourly['timestamp'].values))\n",
    "\n",
    "# log scaling\n",
    "df_code_date_hourly['code_num'] = np.log(df_code_date_hourly['demand'])\n",
    "\n",
    "# MinMaxS scaling\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_code_date_hourly['code_num'] = scaler.fit_transform(df_code_date_hourly['code_num'].values.reshape(-1, 1))\n",
    "\n",
    "# \n",
    "\n",
    "length_of_sequences = 24\n",
    "test_size = 0.1\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = train_test_split(df_code_date_hourly[['code_num']], test_size=test_size,\n",
    "                                                        n_prev=length_of_sequences)\n",
    "\n",
    "# row_data = df_code_date_hourly['demand'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is uploaded to: s3://sagemaker-ap-northeast-1-481470706855/dataset/pytorch\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"./pytorch_data\", exist_ok = True)\n",
    "\n",
    "# np.savez('./data/train', image=X_train, label=y_train)\n",
    "# np.savez('./data/test', image=X_test, label=y_test)\n",
    "df_code_date_hourly = pd.read_csv('./code_run_num_hourly.csv')\n",
    "df_code_date_hourly.to_csv('pytorch_data/train_data.csv')\n",
    "# np.savez('./data/row_data', row_data=row_data)\n",
    "joblib.dump(scaler, './pytorch_data/scaler.save')\n",
    "\n",
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "input_data = sagemaker_session.upload_data(path='./pytorch_data', bucket=bucket_name, key_prefix='dataset/pytorch')\n",
    "print('Training data is uploaded to: {}'.format(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニングジョブの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-26 00:53:13 Starting - Starting the training job...\n",
      "2019-11-26 00:53:14 Starting - Launching requested ML instances......\n",
      "2019-11-26 00:54:23 Starting - Preparing the instances for training...\n",
      "2019-11-26 00:55:02 Downloading - Downloading input data...\n",
      "2019-11-26 00:55:33 Training - Downloading the training image...\n",
      "2019-11-26 00:56:08 Training - Training image download completed. Training in progress..\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-11-26 00:56:09,863 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-11-26 00:56:09,866 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-11-26 00:56:09,879 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-11-26 00:56:12,936 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-11-26 00:56:13,367 sagemaker-containers INFO     Module training does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-11-26 00:56:13,368 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-11-26 00:56:13,368 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-11-26 00:56:13,368 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: training\n",
      "  Building wheel for training (setup.py): started\n",
      "  Building wheel for training (setup.py): finished with status 'done'\n",
      "  Created wheel for training: filename=training-1.0.0-py2.py3-none-any.whl size=11720 sha256=6edefb96f41dd178cb0b60270bb720de07103f01a9378d134f338855e74fa603\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sf0y_xun/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built training\u001b[0m\n",
      "\u001b[31mInstalling collected packages: training\u001b[0m\n",
      "\u001b[31mSuccessfully installed training-1.0.0\u001b[0m\n",
      "\u001b[31mWARNING: You are using pip version 19.3; however, version 19.3.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-11-26 00:56:15,317 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-11-26 00:56:15,331 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 256,\n",
      "        \"num_gpus\": 0,\n",
      "        \"epochs\": 15\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2019-11-26-00-53-12-477\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-1-481470706855/pytorch-training-2019-11-26-00-53-12-477/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"training\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"training.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"batch-size\":256,\"epochs\":15,\"num_gpus\":0}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=training.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=training\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-ap-northeast-1-481470706855/pytorch-training-2019-11-26-00-53-12-477/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":256,\"epochs\":15,\"num_gpus\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2019-11-26-00-53-12-477\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-481470706855/pytorch-training-2019-11-26-00-53-12-477/source/sourcedir.tar.gz\",\"module_name\":\"training\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"training.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--batch-size\",\"256\",\"--epochs\",\"15\",\"--num_gpus\",\"0\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mSM_HP_BATCH-SIZE=256\u001b[0m\n",
      "\u001b[31mSM_HP_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/opt/conda/bin/python -m training --batch-size 256 --epochs 15 --num_gpus 0\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (0.21.2)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.3.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (0.13.2)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.16.4)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (1.9.249)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: botocore<1.13.0,>=1.12.249 in /opt/conda/lib/python3.6/site-packages (from boto3) (1.12.249)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3) (0.9.4)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3) (0.2.1)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.249->boto3) (2.8.0)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.249->boto3) (1.24.2)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.249->boto3) (0.14)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.249->boto3) (1.12.0)\u001b[0m\n",
      "\u001b[31m1 loss: 10.950, training_accuracy: 0.19266, test_accuracy: 0.56973\u001b[0m\n",
      "\u001b[31m2 loss: 0.832, training_accuracy: 0.51972, test_accuracy: 0.54557\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m3 loss: 0.784, training_accuracy: 0.50226, test_accuracy: 0.59347\u001b[0m\n",
      "\u001b[31m4 loss: 0.716, training_accuracy: 0.54517, test_accuracy: 0.58966\u001b[0m\n",
      "\u001b[31m5 loss: 0.708, training_accuracy: 0.56000, test_accuracy: 0.61255\u001b[0m\n",
      "\u001b[31m6 loss: 0.670, training_accuracy: 0.58513, test_accuracy: 0.64095\u001b[0m\n",
      "\u001b[31m7 loss: 0.607, training_accuracy: 0.62751, test_accuracy: 0.67274\u001b[0m\n",
      "\u001b[31m8 loss: 0.571, training_accuracy: 0.64928, test_accuracy: 0.69945\u001b[0m\n",
      "\u001b[31m9 loss: 0.456, training_accuracy: 0.70733, test_accuracy: 0.69224\u001b[0m\n",
      "\u001b[31m10 loss: 0.346, training_accuracy: 0.75823, test_accuracy: 0.74693\u001b[0m\n",
      "\u001b[31m11 loss: 0.275, training_accuracy: 0.81407, test_accuracy: 0.77406\u001b[0m\n",
      "\u001b[31m12 loss: 0.278, training_accuracy: 0.81544, test_accuracy: 0.77830\u001b[0m\n",
      "\u001b[31m13 loss: 0.247, training_accuracy: 0.82890, test_accuracy: 0.77872\u001b[0m\n",
      "\u001b[31m14 loss: 0.266, training_accuracy: 0.82659, test_accuracy: 0.78423\u001b[0m\n",
      "\n",
      "2019-11-26 00:57:10 Uploading - Uploading generated training model\n",
      "2019-11-26 00:57:10 Completed - Training job completed\n",
      "\u001b[31m15 loss: 0.237, training_accuracy: 0.83973, test_accuracy: 0.78211\u001b[0m\n",
      "\u001b[31mSaving the model.\u001b[0m\n",
      "\u001b[31m2019-11-26 00:57:01,835 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 128\n",
      "Billable seconds: 128\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "hyper_param = {\n",
    "    'batch-size': 256,\n",
    "    'epochs': 15,\n",
    "    'num_gpus': 0\n",
    "}\n",
    "\n",
    "role = get_execution_role()\n",
    "estimator = PyTorch(entry_point='./pytorch_data/training.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.2.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.m4.xlarge',\n",
    "                    hyperparameters=hyper_param)\n",
    "\n",
    "estimator.fit({'training': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エンドポイントの呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, _), (exc, _) = train_test_split(df_code_date_hourly[['demand']], test_size=test_size,\n",
    "                                                        n_prev=length_of_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = exc[0].reshape(1, 24, 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 181}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "inp = json.dumps(dd)\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName='pytorch-training-2019-11-26-00-53-12-477',\n",
    "    Body=inp,\n",
    "    ContentType='application/json',\n",
    "    Accept='application/json'\n",
    ")\n",
    "\n",
    "body = response['Body']\n",
    "json.load(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
